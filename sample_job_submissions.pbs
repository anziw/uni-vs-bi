#!/bin/bash
### A name for the job - No spaces allowed
#PBS -N Python_Script
### Specify how many nodes and how many processors
#PBS -l nodes=1:ppn=4
### Specify the maximum time allowed for the job to run in each node - example 24 hours
#PBS -l walltime=24:00:00
### Specify Memory Limit
#PBS -l mem=32gb
### Specify a file for the console output - if any
#PBS -o localhost:/home/awang1/pbs/PythonScripts/outcomes/simple_outcome.log
### Specify a file for the console error output - if any 
#PBS -e localhost:/home/awang1/pbs/PythonScripts/errors/simple_error.log
### Receive an email when the job begins execution (b), when it ends (e), and when it encounters an error (a)
#PBS -m bae
### Specify an email for pds@colgate.edu to send notifications
#PBS -M awang1@colgate.edu
### Use submission environment, including all shell variables.
#PBS -V
###          ###
# Queue States #
###          ###
##  Q (queued): The job is waiting in the queue to be scheduled.
##  R (running): The job is running on a compute node.
##  H (held): The job is in a held state and is not eligible to run.
##  E (error): The job has encountered an error and cannot be run.
##  T (moved): The job has been moved to a new location in the queue.
##  W (waiting): The job is waiting for its execution window.
##  S (suspended): The job has been suspended by the system or the user.
##  C (completed): The job has completed successfully.
##
##  qsub example.pbs : submit the example.pbs job to the queue
##  qstat -u awang1 : check submitted job status for specific user
##  qstat -f <jobID> : check job queue output
##  qdel <jobID> : delete job (only allowed for jobs you (awang1) submitted)
###
### Start job from the directory it was submitted.
cd $PBS_O_WORKDIR

# Activate the python environment for crest
source /local/JupyterHub/bin/activate && conda activate nlp
### The following is the command to run on each processor (equivalent to worker in matlab).
## python3.11 /path/to/PythonScript
python main1.py config1.yaml
python main2.py config2.yaml
python main3.py config3.yaml
....
# i will eventually have many pbs files because we evaluate at least 50 models. for each new pbs file, i will make a copy of main and config and use each pbs to run a pair of (main, config).
